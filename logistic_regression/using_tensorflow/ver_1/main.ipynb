{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "#\n",
    "num_of_data1 = 100\n",
    "num_of_data2 = 100\n",
    "num_of_data = num_of_data1 + num_of_data2\n",
    "#\n",
    "num_of_data1_train = int(num_of_data1 * .2)\n",
    "num_of_data2_train = int(num_of_data2 * .2)\n",
    "num_of_data_train = num_of_data1_train + num_of_data2_train\n",
    "#\n",
    "num_of_features = 2\n",
    "#\n",
    "x1 = tf.random.normal(shape=[num_of_data1,num_of_features],mean=[1,3],stddev=1.0)\n",
    "x2 = tf.random.normal(shape=[num_of_data2,num_of_features],mean=[3,1],stddev=1.0)\n",
    "X = tf.experimental.numpy.vstack((x1,x2))\n",
    "#\n",
    "y1 = tf.zeros(shape=[num_of_data1,1])\n",
    "y2 = tf.ones(shape=[num_of_data2,1])\n",
    "Y = tf.experimental.numpy.vstack((y1,y2))\n",
    "p = Y\n",
    "#\n",
    "x1_train = tf.random.normal(shape=[num_of_data1_train,num_of_features],mean=[2,3],stddev=1.0)\n",
    "x2_train = tf.random.normal(shape=[num_of_data2_train,num_of_features],mean=[5,1],stddev=1.0)\n",
    "X_train = tf.experimental.numpy.vstack((x1_train,x2_train))\n",
    "#\n",
    "y1_train = tf.zeros(shape=[num_of_data1_train,1])\n",
    "y2_train = tf.ones(shape=[num_of_data2_train,1])\n",
    "Y_train = tf.experimental.numpy.vstack((y1_train,y2_train))\n",
    "#\n",
    "plt.scatter(X[:,0],X[:,1], c=Y[:,0])\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=Y_train[:,0])\n",
    "plt.show()\n",
    "#\n",
    "#\n",
    "w = tf.Variable(tf.random.normal(shape=(num_of_features, 1)))\n",
    "b = tf.Variable(tf.random.normal(shape=(num_of_data, 1)))\n",
    "#\n",
    "Y_hat = tf.zeros(shape=(num_of_data, 1))\n",
    "p_hat = tf.zeros(shape=(num_of_data, 1))\n",
    "grad_L = {\"dw\": 0.0, \"db\" : 0.0}\n",
    "#\n",
    "# initialize hyper parameter\n",
    "alpha = 0.001\n",
    "lamb = 0.001\n",
    "#\n",
    "#\n",
    "def forward_propagation(xx):\n",
    "    global Y_hat, p_hat\n",
    "    Y_hat = matmul(xx,w) + b\n",
    "    p_hat = sigmoid(Y_hat)\n",
    "    return None\n",
    "#\n",
    "#\n",
    "def update_params():\n",
    "    global w, b\n",
    "    w = w - alpha * (grad_L[\"dw\"] + lamb * w)\n",
    "    b = b - alpha * grad_L[\"db\"]\n",
    "    return None\n",
    "#\n",
    "#\n",
    "def calc_loss():\n",
    "    return sum(\n",
    "        -(p*ln(p_hat)+(1.-p)*ln(1.-p_hat))/num_of_data\n",
    "    )\n",
    "#\n",
    "#\n",
    "def calc_accuracy(xx,yy):\n",
    "    forward_propagation(xx)\n",
    "    prediction = tf.zeros(p_hat.shape)\n",
    "    prediction[p_hat >= 0.9] = 1\n",
    "    accuracy1 = (1.0 - tf.math.reduce_mean(tf.abs(prediction-yy))) * 100\n",
    "    return accuracy1\n",
    "#\n",
    "#\n",
    "def shuffle_data():\n",
    "    tf.random.shuffle(seed=1000,value=X)\n",
    "    tf.random.shuffle(seed=1000,value=Y)\n",
    "    return None\n",
    "#\n",
    "#\n",
    "@tf.function\n",
    "def calc_gradient():\n",
    "    global grad_L\n",
    "    with tf.GradientTape() as tape:\n",
    "        forward_propagation(X)\n",
    "        loss = calc_loss()\n",
    "        grad_L = tape.gradient(loss, [w,b])\n",
    "    return None\n",
    "#\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    num_of_epochs = 100\n",
    "    num_of_iterations = 10000\n",
    "    total_loss = []\n",
    "    for epoch in range(num_of_data):\n",
    "        shuffle_data()\n",
    "        for i in range(num_of_iterations):\n",
    "            calc_gradient()\n",
    "            update_params()\n",
    "            if i % 100 == 0:\n",
    "                print(f'epoch is {epoch}, iter# is {i}')\n",
    "                total_loss.append(calc_loss())\n",
    "                print(f'loss at iteration {i}: {calc_loss()}')\n",
    "                print(f'test accuracy: {calc_accuracy(X_train, Y_train)}')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.yscale('log')\n",
    "    plt.plot(f\"sum of iter * {int(1e+2)}\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"logistic regression\")\n",
    "    plt.show()\n",
    "#\n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}